{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "from math import  pi\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from emoji import core\n",
    "\n",
    "import re\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import gutenberg\n",
    "from emoji import core\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df_com = pd.read_csv('./data/cafe_comment.csv')\n",
    "df_main = pd.read_csv('./data/cafe_main.csv')\n",
    "df_com.drop(['text_number'], axis=1, inplace=True)\n",
    "df_com['etc'] = '댓글'\n",
    "df_main.drop(['date','click','text_number'], axis=1, inplace=True)\n",
    "df_main['etc'] = '본문'\n",
    "df_com.rename(columns={'comment' : 'text'}, inplace=True)\n",
    "df = pd.concat([df_com,df_main])\n",
    "df.sort_values('title')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop_duplicates(['text'], inplace=True)\n",
    "\n",
    "display(df.isnull().sum())\n",
    "df.fillna('_',inplace=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop_words\n",
    "with open('./data/stop_words.txt', encoding='utf-8') as f:\n",
    "    stop_words = f.readlines()\n",
    "stop_words = [line.rstrip('\\n') for line in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 전처리 (+전처리 함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그 제거\n",
    "def del_tag_check(text):\n",
    "    text = re.sub('http:', '', text)\n",
    "    text = re.sub('comhttpsm.', '', text)\n",
    "    text = re.sub(r'(\\d{2,4})-(\\d{3,4})-?(\\d{0,4})?', '', text) # 전화번호 제거\n",
    "    text = re.sub('blog.', '', text)\n",
    "    text = re.sub('naver.', '', text)\n",
    "    text = re.sub('co. kr', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 표현 전처리\n",
    "def combine_check(text):\n",
    "\n",
    "    text = re.sub(r'밀크티초등(?!학)', '밀크티', text)\n",
    "    text = re.sub('초등\\s?밀크티', '밀크티', text)\n",
    "    text = re.sub('밀크티\\s?아이', '밀크티', text)\n",
    "    text = re.sub(r'아이스크림(?!홈)', '홈런', text)\n",
    "    # 명사\n",
    "    # text = re.sub('할미','할머니', text)\n",
    "    # text = re.sub('티비','텔레비전', text)\n",
    "\n",
    "    text = re.sub('애','아이', text)\n",
    "    text = re.sub('ebs','이비에스', text)\n",
    "    text = re.sub('앨','엘', text)\n",
    "    text = re.sub('앰','엠', text)\n",
    "    text = re.sub('전용학습기','패드', text)\n",
    "    text = re.sub('태블릿','패드', text)\n",
    "    text = re.sub('테블릿','패드', text)\n",
    "    text = re.sub('빨간팬','빨간펜', text)\n",
    "    text = re.sub('온니원','온리원', text)\n",
    "    text = re.sub('아이켄두','아이캔두', text)\n",
    "    text = re.sub('와캠','와이즈캠프', text)\n",
    "    #쿠키? 는 난 안해도 될듯...\n",
    "    \n",
    "    text = re.sub('4(세|살)', '유아', text)\n",
    "    text = re.sub('5(세|살)', '유아', text)\n",
    "    text = re.sub('6(세|살)', '유아', text)\n",
    "    text = re.sub('7(세|살)', '유아', text)\n",
    "    text = re.sub('예비\\s?초등', '유아', text)\n",
    "    text = re.sub('8(세|살)', '초등저', text)\n",
    "    text = re.sub('9(세|살)', '초등저', text)\n",
    "    text = re.sub('(초|초등)1', '초등저', text)\n",
    "    text = re.sub('1학년', '초등저', text)\n",
    "    text = re.sub('(초|초등)2', '초등저', text)\n",
    "    text = re.sub('2학년', '초등저', text)\n",
    "    text = re.sub('(초|초등)3', '초등저', text)\n",
    "    text = re.sub('3학년', '초등저', text)\n",
    "    text = re.sub('(초|초등)4', '초등고', text)\n",
    "    text = re.sub('4학년', '초등고', text)\n",
    "    text = re.sub('(초|초등)5', '초등고', text)\n",
    "    text = re.sub('5학년', '초등고', text)\n",
    "    text = re.sub('(초|초등)6', '초등고', text)\n",
    "    text = re.sub('6학년', '초등고', text)\n",
    "    text = re.sub('(초등|초등학교)\\s?초등고', '초등고', text)\n",
    "    text = re.sub('(초등|초등학교)\\s?초등저', '초등저', text)\n",
    "\n",
    "    special_word = ['[*]','o','@', 'x', '0']\n",
    "\n",
    "    for i in special_word:\n",
    "        text = re.sub(f'아이{i}두','아이캔두', text)\n",
    "        text = re.sub(f'아이캔{i}','아이캔두', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 특수문자 및 초성 전처리 함수\n",
    "\n",
    "def company_re(text, word, chosung:bool, loc=None): \n",
    "\n",
    "# chosung : 앞 두글자만 적어 놓은 글을 정규식으로 정리 할 때 문제가 없나요 ?\n",
    "# True : 확인, False : 두글자 확인 x (ex: 밀크티, 윙크 : 문제 있음. False 입력)\n",
    "# loc : chosung이 False 일 때, 앞 두글자 중 정규식을 사용 할 위치 지정 \n",
    "# 아이(캔두) : 아-ㅇ = 0, 이-ㅇ= 1 이므로 와이(즈캠프) 겹치지 않기 위해 loc=1 입력\n",
    "\n",
    "# 영어는 모두 소문자화 했다고 가정 (lower())\n",
    "    if chosung == False and loc is None:\n",
    "        print(f\"'초성 테스트를 False로 입력 시 loc값을 입력해 줘야 합니다. \\n chosung = {chosung}, loc = {loc} \\n loc은 정규식을 이용할 초성의 위치입니다. (ex. ㅁ크 -> 밀크 : loc = 0\")\n",
    "    elif chosung == False:\n",
    "        if loc < 0 or loc > 1:\n",
    "            print(f'loc값이 잘못되었습니다. 입력한 loc 값 : {loc}')\n",
    "\n",
    "    if len(word) < 2:\n",
    "        return f'!Error! 검색 단어가 너무 짧습니다. 검색 단어 : {word}'\n",
    "        \n",
    "    cho1 = CHOSUNG_extraction(word)[0]\n",
    "    cho2 = CHOSUNG_extraction(word)[1]\n",
    "\n",
    "    special_word = ['[*]','o','@', 'x', '0']\n",
    "\n",
    "    if len(word) == 2:\n",
    "        if chosung:\n",
    "            text = re.sub(cho1+cho2, word[:], text)\n",
    "            text = re.sub(cho1+word[1], word[:], text)\n",
    "            text = re.sub(word[0]+cho2, word[:], text)\n",
    "\n",
    "            for i in range(len(word)):\n",
    "                for re_w in special_word:\n",
    "                    re_sen = word[:i] + re_w + word[i+1:]\n",
    "\n",
    "                    text = re.sub(re_sen,word,text)\n",
    "        \n",
    "            return text\n",
    "\n",
    "\n",
    "        else:\n",
    "            text = re.sub(cho1+cho2, word[:], text)\n",
    "\n",
    "            if loc == 0:\n",
    "                text = re.sub(cho1+word[1], word[:], text) # ㅇ이, 아이, text\n",
    "                for re_w in special_word:\n",
    "                    re_sen = re_w + word[1]\n",
    "                    text = re.sub(re_sen, word[:], text)\n",
    "\n",
    "            elif loc == 1:\n",
    "                text = re.sub(word[0]+cho2, word[:], text) # 아ㅇ, 아이, text\n",
    "                for re_w in special_word:\n",
    "                    re_sen = word[0] + re_w\n",
    "                    text = re.sub(re_sen, word[:], text)\n",
    "\n",
    "            return text\n",
    "        \n",
    "\n",
    "\n",
    "    elif len(word) > 2:\n",
    "        if chosung:\n",
    "            text = re.sub(cho1+cho2, word[0:2], text)\n",
    "            text = re.sub(cho1+word[1], word[0:2], text)\n",
    "            text = re.sub(word[0]+cho2, word[0:2], text)\n",
    "            text = re.sub(rf'{word[0:2]}(?!{word[2]})', word[:], text)\n",
    "            \n",
    "            for i in range(len(word)):\n",
    "                for re_w in special_word:\n",
    "                    re_sen = word[:i] + re_w + word[i+1:]\n",
    "                    text = re.sub(re_sen,word,text)\n",
    "\n",
    "            for i in range(1, len(word)):\n",
    "                for re_w in special_word:\n",
    "                    re_sen = word.replace(word[i], re_w).replace(word[i-1], re_w)\n",
    "                    text = re.sub(re_sen, word, text)\n",
    "\n",
    "            if len(word) > 3:\n",
    "                for i in range(len(word)):\n",
    "                    for re_w in special_word:\n",
    "                        re_sen = word.replace(word[i], re_w).replace(word[i-1], re_w).replace(word[i-2], re_w)\n",
    "                        text = re.sub(re_sen, word, text)\n",
    "\n",
    "            return text\n",
    "\n",
    "\n",
    "        else:\n",
    "            text = re.sub(cho1+cho2, word[0:2], text)\n",
    "            if loc == 0:\n",
    "                text = re.sub(cho1+word[1], word[0:2], text)\n",
    "                text = re.sub(rf'{word[0:2]}(?!{word[2]})', word[:], text)\n",
    "\n",
    "                for i in range(len(word)):\n",
    "                    for re_w in special_word:\n",
    "                        re_sen = word[:i] + re_w + word[i+1:]\n",
    "                        text = re.sub(re_sen,word,text)\n",
    "\n",
    "                for i in range(1, len(word)):\n",
    "                    for re_w in special_word:\n",
    "                        re_sen = word.replace(word[i], re_w).replace(word[i-1], re_w)\n",
    "                        text = re.sub(re_sen, word, text)\n",
    "\n",
    "                if len(word) > 3:\n",
    "                    for i in range(len(word)):\n",
    "                        for re_w in special_word:\n",
    "                            re_sen = word.replace(word[i], re_w).replace(word[i-1], re_w).replace(word[i-2], re_w)\n",
    "                            text = re.sub(re_sen, word, text)\n",
    "\n",
    "                return text\n",
    "\n",
    "\n",
    "            elif loc == 1:\n",
    "                text = re.sub(word[0]+cho2, word[0:2], text)\n",
    "                text = re.sub(rf'{word[0:2]}(?!{word[2]})', word[:], text)\n",
    "\n",
    "                for i in range(len(word)):\n",
    "                    for re_w in special_word:\n",
    "                        re_sen = word[:i] + re_w + word[i+1:]\n",
    "                        text = re.sub(re_sen,word,text)\n",
    "\n",
    "                for i in range(1, len(word)):\n",
    "                    for re_w in special_word:\n",
    "                        re_sen = word.replace(word[i], re_w).replace(word[i-1], re_w)\n",
    "                        text = re.sub(re_sen, word, text)\n",
    "\n",
    "                if len(word) > 3:\n",
    "                    for i in range(len(word)):\n",
    "                        for re_w in special_word:\n",
    "                            re_sen = word.replace(word[i], re_w).replace(word[i-1], re_w).replace(word[i-2], re_w)\n",
    "                            text = re.sub(re_sen, word, text)\n",
    "\n",
    "                return text\n",
    "\n",
    "# 초성 찾기 함수\n",
    "def CHOSUNG_extraction(text):\n",
    "\n",
    "    CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', \n",
    "                    'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', \n",
    "                    'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    chosung_str = ''\n",
    "    for w in list(text):\n",
    "        if '가'<=w<='힣':\n",
    "            # 588개 마다 초성이 바뀜.\n",
    "            chosung_num = (ord(w) - ord('가'))//588\n",
    "            chosung_str = chosung_str + CHOSUNG_LIST[chosung_num]\n",
    "\n",
    "        else:\n",
    "            chosung_str = chosung_str + w\n",
    "            \n",
    "    return chosung_str\n",
    "\n",
    "# 특수문자 제거\n",
    "def special_check(text):\n",
    "    # 특수 기호 제거\n",
    "    text = re.sub('[-=+,#/\\?:^$@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\n★▲;|]',' ', text)\n",
    "\n",
    "    # '\\E' 모양 제거\n",
    "    text = re.sub('[\\a-zA-Z]. ',' ',text)\n",
    "\n",
    "    # # 이모티콘 제거\n",
    "    # text = core.replace_emoji(text, replace='')\n",
    "\n",
    "    # 줄임말 치환\n",
    "    text = re.sub('와캠', '와이즈', text)\n",
    "    text = re.sub('와이즈캠프', '와이즈', text)\n",
    "    text = re.sub('싱크빅', '씽크빅', text)\n",
    "    text = re.sub('웅진\\s?씽크빅', '씽크빅', text)\n",
    "    text = re.sub('웅진\\s?스마트올', '스마트올', text)\n",
    "    text = re.sub('이캔두', '아이캔두', text)\n",
    "\n",
    "    # 자/모음만 남은 경우 제거\n",
    "    text = re.sub('[ㄱ-ㅎ]+', '', text)\n",
    "    text = re.sub('[ㅏ-ㅣ]+', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = ['밀크티', '엘리하이', '엠베스트','윙크', '빨간펜', \n",
    "                '온리원', '홈런', '와이즈캠프','스마트올',\n",
    "                '와캠', '싱크빅', '씽크빅', '웅진', '이캔두']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x : del_tag_check(x))\n",
    "df['title'] = df['title'].apply(lambda x : del_tag_check(x))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x : combine_check(x))\n",
    "df['title'] = df['title'].apply(lambda x : combine_check(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in tqdm(company_list):\n",
    "    \n",
    "    # 전처리 예외처리 (*크)\n",
    "    if company == '밀크티' or company == '윙크':\n",
    "        df['text'] = df['text'].apply(lambda x : company_re(x, company, False, 0))\n",
    "        df['title'] = df['title'].apply(lambda x : company_re(x, company, False, 0))\n",
    "\n",
    "    # elif company == '와이즈캠프' or company == '아이캔두':\n",
    "    #     df['text'] = df['text'].apply(lambda x : company_re(x, company, False, 1))\n",
    "    #     df['title'] = df['title'].apply(lambda x : company_re(x, company, False, 1))\n",
    "\n",
    "    else:\n",
    "        df['text'] = df['text'].apply(lambda x : company_re(x, company, True))\n",
    "        df['title'] = df['title'].apply(lambda x : company_re(x, company, True))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x : special_check(x))\n",
    "df['title'] = df['title'].apply(lambda x : special_check(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DateFrame 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 존재 여부\n",
    "# company_list.append('아이캔두')\n",
    "\n",
    "for key in tqdm(company_list):\n",
    "    test_list = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if key in df['text'][i] or key in df['title'][i]: # 내용 혹은 제목에 key값이 들어 있는지\n",
    "            test_list.append(True)\n",
    "\n",
    "        else:\n",
    "            test_list.append(False)\n",
    "\n",
    "    df[key] = test_list # 데이터프레임에 'key' column 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = pd.DataFrame()\n",
    "\n",
    "for company in company_list:\n",
    "    df_piece = df[df[company] == True]\n",
    "    remove = ['board_name', 'cafe_id']\n",
    "    # remove = list(df_piece.columns)\n",
    "    # remove.remove('text')\n",
    "    # remove.remove('title')\n",
    "    # remove.remove('yyyy')\n",
    "    # remove.remove('mm')\n",
    "    df_piece.drop(remove, axis=1, inplace=True)\n",
    "    df_piece['company'] = company\n",
    "\n",
    "    df_sentiment = pd.concat([df_sentiment, df_piece], axis=0)\n",
    "\n",
    "df_sentiment.reset_index(drop=True, inplace=True)\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 (Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍/부정문 사전 필요\n",
    "\n",
    "posi_path = \"./data/positive_words.txt\"\n",
    "nega_path = \"./data/negative_words.txt\"\n",
    "\n",
    "with open(posi_path, encoding='utf-8') as f:\n",
    "    positive_words = f.readlines()\n",
    "\n",
    "with open(nega_path, encoding='utf-8') as f:\n",
    "    negative_words = f.readlines()\n",
    "\n",
    "positive_words = [line.rstrip('\\n') for line in positive_words]\n",
    "negative_words = [line.rstrip('\\n') for line in negative_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전에서 불필요한 단어 없애기 (사전 자체를 미리 수정하면 이 코드 없어도 될듯...)\n",
    "\n",
    "try:\n",
    "    pasitive_words = pasitive_words.remove([''])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    negative_words = negative_words.remove(['저는', '수'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주제별 검색어 리스트 (key_dict) ['가격', '품질',' 컨텐츠', '평가', '아이', '학부모']\n",
    "\n",
    "가격 = '가격'\n",
    "가격_list = ['비용','가격','교육비','약정','돈','할인','계약','영사','금액','구매','값','위약금','해지','구입','영업','렌트','무료','체험']\n",
    "\n",
    "품질 = '품질'\n",
    "품질_list = ['패드', '스마트','기기','온라인','위약금','제품','렌트','키보드','갤럭시','오류','먹통','태블릿','시스템','퀄리티']\n",
    "\n",
    "컨텐츠 = '컨텐츠'\n",
    "컨텐츠_list = ['영어','수학','학습지','문제','과학','교재','국어',\n",
    "        '인강','컨텐츠','사회','개념','한글','한자','영상','미술','파닉스',\n",
    "        '논술','독해','심화','리딩','게임','프로그램','예체능','콘텐츠','동영상',\n",
    "        '국사','역사','한국사','도서','자료','발음','원어민','미디어','동화','진단','구구단','난이도',\n",
    "        '퀄리티','독후','코딩']\n",
    "\n",
    "평가 = '평가'\n",
    "평가_list = ['진도','평가','시험','만점','체크','실력','오답','중간','기말','진단','테스트','성적','풀이','채점','정답','등급','수행','경시대회']\n",
    "\n",
    "아이 = '아이'\n",
    "아이_list = ['아이','애','공부','학습','습관','우리','첫째','둘째','셋째','본인','초등학생','초등','초딩','중학생','중등','중딩','쌍둥이','자기','혼자','딸','아들']\n",
    "\n",
    "학부모 = '학부모'\n",
    "학부모_list = ['엄마','소개','지인','부모','자녀','남편','아빠','어머님','아버님','잔소리','신랑','어른','욕심']\n",
    "\n",
    "key_dict = {가격:가격_list, 품질:품질_list, 컨텐츠:컨텐츠_list, 평가:평가_list, 아이:아이_list, 학부모:학부모_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_start = time.time()\n",
    "\n",
    "status = pd.DataFrame(columns=['Company'])\n",
    "status['Company'] = company_list\n",
    "\n",
    "for subject in key_dict:\n",
    "    keyword = key_dict.get(subject)\n",
    "\n",
    "    print('-----------------------')\n",
    "    if len(subject) == 2:\n",
    "        print(f'| 검색 : {subject}          |')\n",
    "    elif len(subject) == 3:\n",
    "        print(f'| 검색 : {subject}        |')\n",
    "    print('-----------------------')\n",
    "\n",
    "    firm = df_sentiment.get('company')\n",
    "    text = df_sentiment.get('text')\n",
    "    text_key = []\n",
    "\n",
    "    company = {firm[0]:text[0]}\n",
    "    num = 0\n",
    "    for i in tqdm(range(len(firm))):\n",
    "        \n",
    "        if company.get(firm[i]) != None:\n",
    "            \n",
    "            if any(keyword in text[i] for keyword in keyword):\n",
    "\n",
    "                company[firm[i]] = company.get(firm[i]) + \"\\n\" + text[i]\n",
    "                text_key.append(text[i])\n",
    "\n",
    "\n",
    "            else:\n",
    "                num += 1\n",
    "\n",
    "        else:\n",
    "            if any(keyword in text[i] for keyword in keyword):\n",
    "                company[firm[i]] = text[i]\n",
    "                text_key.append(text[i])\n",
    "            else:\n",
    "                num += 1\n",
    "\n",
    "    print(f'{len(firm)} 개의 데이터 중 {subject} 데이터 개수 : {len(firm) - num}')\n",
    "\n",
    "    # 토큰화\n",
    "    tokens=[]\n",
    "    for f, t in company.items():\n",
    "        token=word_tokenize(t)\n",
    "        tokens.append([f,token])\n",
    "\n",
    "    # sentiment 점수\n",
    "    sentiment_firm=[]\n",
    "    posi_firm=[]\n",
    "    nega_firm=[]\n",
    "    round_ = 3\n",
    "    posi_words = []\n",
    "    nega_words = []\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for token in tokens:\n",
    "        posi_word = []\n",
    "        nega_word = []\n",
    "        firm=token[0]\n",
    "        sentiment=0\n",
    "        count=0\n",
    "\n",
    "        posi = 0\n",
    "        nega = 0\n",
    "\n",
    "        for t in tqdm((token[1])):\n",
    "            if len(t) > 1:\n",
    "                # if t in positive_words:\n",
    "                if any(word in t for word in positive_words): # 사전에 morphs를 써서 세분화 분석을 진행해 볼까... 했는데 정확도가 떨어지기 때문에 X\n",
    "                    posi_word.append(t)\n",
    "                    sentiment+=1\n",
    "                    posi += 1\n",
    "                    count+=1\n",
    "\n",
    "                    # if count < 20:\n",
    "                    #     print('테스트중 : ', t)\n",
    "                    # else : pass\n",
    "                \n",
    "                # elif t in negative_words:\n",
    "                elif any(word in t for word in negative_words):\n",
    "                    nega_word.append(t)\n",
    "                    sentiment -=1\n",
    "                    nega += 1\n",
    "                    count+=1\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "            #     print(t, '테스트...')\n",
    "            \n",
    "            \n",
    "        \n",
    "        sentiment_firm.append([firm,round(sentiment/count,round_)])\n",
    "        posi_firm.append([firm,round(posi/count,round_)])\n",
    "        nega_firm.append([firm,round(nega/count,round_)])\n",
    "        posi_words = posi_words + posi_word\n",
    "        nega_words = nega_words + nega_word\n",
    "        print(f'{firm} token 개수 : ', len(token[1]))\n",
    "        print(f'{firm} sentiment filtering 횟수 : ', count)\n",
    "    sentiment_words = posi_words + nega_words\n",
    "    end = time.time()\n",
    "\n",
    "    print('긍정점수 : ', posi_firm)\n",
    "    print()\n",
    "    print('부정점수 : ', nega_firm)\n",
    "    print()\n",
    "    print('종합점수 : ', sentiment_firm)\n",
    "    print()\n",
    "    # print('데이터 수 : ', len(sentiment_words))\n",
    "    print('걸린 시간 : ', round(end - start, round_), '초')\n",
    "\n",
    "    # 빈출어\n",
    "\n",
    "    # all nouns\n",
    "    nouns = []\n",
    "    remove_nouns = []\n",
    "    for i in (sentiment_words):\n",
    "        nouns = nouns + mecab.nouns(i)\n",
    "\n",
    "    for i in nouns:\n",
    "        if len(i) < 2:\n",
    "            remove_nouns.append(i)\n",
    "\n",
    "    for i in remove_nouns:\n",
    "        nouns.remove(i)\n",
    "\n",
    "    print('all sentiment words : \\n', Counter(nouns).most_common(10))\n",
    "\n",
    "    # positive nouns\n",
    "    nouns = []\n",
    "    remove_nouns = []\n",
    "    for i in (posi_words):\n",
    "        nouns = nouns + mecab.nouns(i)\n",
    "\n",
    "    for i in nouns:\n",
    "        if len(i) < 2:\n",
    "            remove_nouns.append(i)\n",
    "\n",
    "    for i in remove_nouns:\n",
    "        nouns.remove(i)\n",
    "\n",
    "    print('positive sentiment words : \\n', Counter(nouns).most_common(10))\n",
    "\n",
    "    # negative nouns\n",
    "    nouns = []\n",
    "    remove_nouns = []\n",
    "    for i in (nega_words):\n",
    "        nouns = nouns + mecab.nouns(i)\n",
    "\n",
    "    for i in nouns:\n",
    "        if len(i) < 2:\n",
    "            remove_nouns.append(i)\n",
    "\n",
    "    for i in remove_nouns:\n",
    "        nouns.remove(i)\n",
    "\n",
    "    print('negative sentiment words : \\n', Counter(nouns).most_common(10))\n",
    "\n",
    "    # # 막대 그래프\n",
    "    # a=[]\n",
    "    # for firm in sentiment_firm:\n",
    "    #     a.append(firm[1]*100)\n",
    "    # X=np.arange(len(a))\n",
    "\n",
    "    # plt.title(f\"preference for {subject}(%)\",fontsize=15)\n",
    "    # # plt.xticks()\n",
    "    # plt.ylim(0, 100)\n",
    "    # plt.xticks([0, 1, 2], labels=['MilkT','Homerun','Wink'])\n",
    "    # # plt.xlabel('..')\n",
    "    # bar = plt.bar(X,a, color= ['cornflowerblue','bisque','thistle'], alpha = 1.0, width=0.5)\n",
    "\n",
    "    # for persent in bar:\n",
    "    #     height = persent.get_height()\n",
    "    #     plt.text(persent.get_x() + persent.get_width()/2.0, height, '%.1f' % height, ha='center', va='bottom', size = 10)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "# 육각형 그리기 준비 (시각화 용 dataframe 형성)\n",
    "    status_list = []\n",
    "    for len_key in range(len(company_list)):\n",
    "        status_list.append(sentiment_firm[len_key][1]*100)\n",
    "    status[subject] = status_list\n",
    "    # status[subject] = [sentiment_firm[0][1]*100,sentiment_firm[1][1]*100,sentiment_firm[2][1]*100]\n",
    "\n",
    "# @@@@ 한글 폰트 깨져서 임시로 넣은 코드... 삭제 예정\n",
    "status.rename(columns={'가격' : 'price', '품질' : 'quality','컨텐츠' : 'contents', '평가' : 'test', '아이' : 'children', '학부모' : 'parents'}, inplace=True)\n",
    "status['Company'] = ['MilkT',' Elihigh', 'Mbest', 'Wink', 'Redpen', 'Onlyone', 'Homerun', 'Wisecamp', 'Smartall', 'Reading_gate', 'Icando']\n",
    "\n",
    "# company 분야별 점수 최대/최소값 구하기\n",
    "\n",
    "for i in range(len(status)):\n",
    "    for j in status.columns:\n",
    "        if status.iloc[i][j] == status.values[i][1:].max():\n",
    "            # max_option = f'최대값 : {j}({status.iloc[i][j]}점)'\n",
    "            # # @@@@ 한글 폰트 깨져서 임시로 넣은 코드... 삭제 예정\n",
    "            max_option = f'max_iter : {j}({round(status.iloc[i][j], round_)})'\n",
    "        elif status.iloc[i][j] == status.values[i][1:].min():\n",
    "            # min_option = f'최대값 : {j}({status.iloc[i][j]}점)'\n",
    "            # # @@@@ 한글 폰트 깨져서 임시로 넣은 코드... 삭제 예정\n",
    "            min_option = f'min_iter : {j}({round(status.iloc[i][j], round_)})'\n",
    "\n",
    "\n",
    "\n",
    "# 육각형 모양 그림\n",
    "## 따로 그리기\n",
    "labels = status.columns[1:]\n",
    "num_labels = len(labels)\n",
    "subplot_len = math.ceil(len(status)/2)\n",
    "    \n",
    "angles = [x/float(num_labels)*(2*pi) for x in range(num_labels)] ## 각 등분점\n",
    "angles += angles[:1] ## 시작점으로 다시 돌아와야하므로 시작점 추가\n",
    "    \n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(status.index))\n",
    " \n",
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.set_facecolor('white')\n",
    " \n",
    "for i, row in status.iterrows():\n",
    "    color = my_palette(i)\n",
    "    data = status.iloc[i].drop('Company').tolist()\n",
    "    data += data[:1]\n",
    "    \n",
    "    ax = plt.subplot(subplot_len,2,i+1, polar=True)\n",
    "    ax.set_theta_offset(pi / 2) ## 시작점\n",
    "    ax.set_theta_direction(-1) ## 그려지는 방향 시계방향\n",
    "    \n",
    "    plt.xticks(angles[:-1], labels, fontsize=13) ## x축 눈금 라벨\n",
    "    ax.tick_params(axis='x', which='major', pad=15) ## x축과 눈금 사이에 여백을 준다.\n",
    " \n",
    "    ax.set_rlabel_position(0) ## y축 각도 설정(degree 단위)\n",
    "    plt.yticks([0,20,40,60,80,100],['0','20','40','60','80','100'], fontsize=10) ## y축 눈금 설정\n",
    "    plt.ylim(0,100)\n",
    "    \n",
    "    ax.plot(angles, data, color=color, linewidth=2, linestyle='solid') ## 레이더 차트 출력\n",
    "    ax.fill(angles, data, color=color, alpha=0.4) ## 도형 안쪽에 색을 채워준다.\n",
    "    \n",
    "    plt.title(row.Company, size=20, color=color,x=-0.2, y=1.2, ha='left') \n",
    "    plt.text(-0.9,175,f' {max_option} \\n {min_option}')\n",
    "    # plt.text(-0.8,45,'text_location2')    \n",
    " \n",
    "plt.tight_layout(pad=0) ## subplot간 패딩 조절\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "# 이미지 저장 (파일이름 : ()YYYYMMhhmm.png)\n",
    "# 배경 투명 옵션 : transparent = True\n",
    "plt.savefig(str('MilkT'+now.strftime('%Y%m%d%H%M'))+'.png')\n",
    "plt.show()\n",
    "\n",
    "all_time_end = time.time()\n",
    "print('총 걸린 시간 : ',round(all_time_end - all_time_start, round_), '초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
